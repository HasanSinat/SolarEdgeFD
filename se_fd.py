import  requests
import pandas as pd
import  datetime
import sys
import streamlit as st
import io
import xlsxwriter
from streamlit_lottie import st_lottie
from streamlit_lottie import st_lottie_spinner
import os
import streamlit as st
import math
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True) 
def check_password():
    """Returns `True` if the user had a correct password."""
    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if (
            st.session_state["username"] in st.secrets["passwords"]
            and st.session_state["password"]
            == st.secrets["passwords"][st.session_state["username"]]
        ):
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # don't store username + password
            del st.session_state["username"]
        else:
            st.session_state["password_correct"] = False
    if "password_correct" not in st.session_state:
        # First run, show inputs for username + password.
        
        st.text_input("Username", key="username")
        st.text_input(
            "Password", type="password", on_change=password_entered, key="password"
        )
        
        return False
    elif not st.session_state["password_correct"]:
        # Password not correct, show input + error.
        st.text_input("Username",  key="username")
        st.text_input(
            "Password", type="password", on_change=password_entered, key="password"
        )
        st.error("ğŸ˜• User not known or password incorrect")
        return False
    else:
        # Password correct.
        return True
if check_password():
    api_key = st.secrets["SolarEdge_API_KEY"]
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    buffer = io.BytesIO()
    solarEdgePlants = [
        {"id": 2176821, "name": "ABDULLAH YILMAZ GÃœNEÅ GES","ins_date": "13.02.2022"},
        {"id": 1061237,"name": "ALKOR GES" },
        {"id": 603955, "name": "CELAL BAYAR ÃœNÄ°VERSÄ°TESÄ° GES"},
        {"id": 2696896, "name": "ERMAS MADENCILIK"},
        {"id": 2205847, "name": "GALETOS GES"},
        {"id": 1824266, "name": "MEGASUT GES"},
        {"id": 2633601, "name": "MESNEVI GIDA GES"},
        {"id": 2416307, "name": "MOSSDECO GES"},
        {"id": 2321791, "name": "OKT 3 GES"},
        {"id": 521013, "name": "TED DENÄ°ZLÄ° KOLEJÄ° GES"},
        {"id": 2563278, "name": "TRIMLINE/BALOSB GES"},
        ]
    baseUrl="https://monitoringapi.solaredge.com"
    inverterSN = " "
    startTime = "2022-04-01"
    endTime = "2022-04-07"
    inverters = list() #api'den inverterlerin seri no'larÄ±nÄ± Ã§ekip buraya atacak
    frameList = list() #her inverter iÃ§in gelen veriler ayrÄ± dataframelerde depolanÄ±p en son birleÅŸtirilecek
    datelist = list() #girilen uzun tarihler haftalÄ±k tarihlere parÃ§alanacak
    inverter_frame_list = list()
    connected_optimizer = 0
    dataTypes=["totalActivePower","dcVoltage","totalEnergy","temperature","L1Data.acCurrent","L1Data.acVoltage","L1Data.apparentPower","L1Data.activePower","L1Data.reactivePower","L1Data.cosPhi","L2Data.acCurrent","L2Data.acVoltage","L2Data.apparentPower","L2Data.activePower","L2Data.reactivePower","L2Data.cosPhi","L3Data.acCurrent","L3Data.acVoltage","L3Data.apparentPower","L3Data.activePower","L3Data.reactivePower","L3Data.cosPhi"]
    if "selectedDataTypes" not in st.session_state:
        st.session_state["selectedDataTypes"] = dataTypes
    @st.experimental_memo(show_spinner=False)
    def get_key(val):
        for plant in solarEdgePlants:
            if plant["name"] == val:
                return plant["id"]
        return "key doesn't exist"
    @st.experimental_memo(show_spinner=False)
    def get_date(val):
        for plant in solarEdgePlants:
            if plant["name"] == val:
                return plant["ins_date"]
    @st.experimental_memo(show_spinner=False)
    def fetchData(siteID,startTime,endTime,inverterSN,api_key, counter,dataTypes):
        
        response_data = requests.get(f"{baseUrl}/equipment/{siteID}/{inverterSN}/data?startTime={startTime} 08:00:00&endTime={endTime} 19:00:00&api_key={api_key}")
        statusCode = response_data.status_code
        response_data = response_data.json()
           #Api'ye json formatÄ±nda istek atÄ±yorum.
        if statusCode == 200 :
            data = pd.json_normalize(response_data["data"]["telemetries"], )
            data=data[dataTypes + ["date"]  ]
            data["InverterNo"] = f"Inverter {counter}"
            data.fillna(0,inplace=True)
            data = data.groupby(["date", "InverterNo", ]).mean()
        return data
        
    @st.experimental_memo(show_spinner=False)
    def load_lottieurl(url: str):
        r = requests.get(url)
        if r.status_code != 200:
            return None
        return r.json()
    def excelCreator():
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            mixed.to_excel(writer, sheet_name="yield_sheet_Nam")
            writer.save()
            return buffer      
    def csvCreator():
        csv = mixed.to_csv()
        csv = csv.encode('utf-8')
        return csv
    def siteDetailsData (siteID,api_key):
        response = requests.get(f"{baseUrl}/site/{siteID}/details?api_key={api_key}").json()
        data = pd.json_normalize(response["details"])
        return data
    lottie_url_hamster = "https://assets9.lottiefiles.com/packages/lf20_xktjqpi6.json"
    lottie_hamster = load_lottieurl(lottie_url_hamster)

    st.header("SolarEdge Data SihirbazÄ± ğŸ§™")
    st.header("#")
    with st.form(key="Santral SeÃ§im Forumu"):
        
        selectedPlant= st.selectbox(
                "Santarli SeÃ§iniz",
                ("ABDULLAH YILMAZ GÃœNEÅ GES", "ALKOR GES", "CELAL BAYAR ÃœNÄ°VERSÄ°TESÄ° GES","ERMAS MADENCILIK","GALETOS GES","MEGASUT GES","OKT 3 GES","TED DENÄ°ZLÄ° KOLEJÄ° GES","TRIMLINE/BALOSB GES",)
            )   
        siteID = get_key(val = selectedPlant)
        colx, coly = st.columns(2)
        with colx:
            startTime = st.date_input("BaÅŸlangÄ±Ã§ Tarihi", max_value=datetime.datetime.now())
        with coly:
            endTime = st.date_input("BtiÅŸ Tarihi",max_value=datetime.datetime.now())

        st.session_state["selectedDataTypes"] = st.multiselect(label="Data Tipleri", options=dataTypes , default=dataTypes)
        col1, mid, col2 = st.columns([10,39,10])
        with col1:
            submitted = st.form_submit_button("Submit")
        with  col2:
            sitedetails = st.form_submit_button("Site Details")
    with st.expander("Bilgilendirme"):
        st.info("API'de gÃ¼nlÃ¼k istek limiti bulunmaktadÄ±r, bu limit genel Ã§aÄŸrÄ±lar iÃ§in 300, santral numarasÄ± ile ile yapÄ±lan Ã§aÄŸrÄ±lar iÃ§in de ayrÄ±ca 300 olarak belirlenmiÅŸtir.\n GÃ¼nlÃ¼k istek limiti aÅŸÄ±ldÄ±ÄŸÄ±da istek hata dÃ¶ndÃ¼recektir.")
        st.warning("API'Ä±n Ã§alÄ±ÅŸma ÅŸekli toplu veri indirmeye uygun olmadÄ±ÄŸÄ±ndan, veriler her inverter bazÄ±nda verilen tarih aralÄ±ÄŸÄ±nÄ± bir haftalÄ±k bloklara bÃ¶lÃ¼p ardÄ±ndan tÃ¼m datalarÄ± bir araya getirmek suretiyle Ã§alÄ±ÅŸÄ±r, Ornegin 9 inverterli bir tesisten bir aylÄ±k data Ã§ekmek iÃ§in her inverter iÃ§in 4 haftalÄ±k data Ã§ekilip birleÅŸtirilir, seri no'larÄ± Ã§ekmek iÃ§in 1 veriler iÃ§in 36 olmak Ã¼zere toplam 37 istek atÄ±lmÄ±ÅŸ olur.")
    with st.expander("Bellek TemizliÄŸi"):
        st.error("LÃ¼tfen yalnÄ±zca gerekli olduÄŸu durumlarda kullanÄ±nÄ±z..")
        st.info("Bellekteki tÃ¼m verileri temizler, aynÄ± tesiste yapÄ±lacak art arda istekleklerde kullnÄ±lmasÄ± Ã¶nerilir.")
        colx,coly,colz = st.columns(3)
        with coly:
            if st.button("BelleÄŸi Temizle"):
                st.experimental_memo.clear()
    if submitted:
        try:
            response_inventory = requests.get(f"{baseUrl}/site/{siteID}/inventory?api_key={api_key}").json() #Api'ye json formatÄ±nda istek atÄ±yorum.
        except:
            sys.exit("Data AlÄ±namadÄ±, LÃ¼tfen Sonra Tekrar Deneyiniz.")

        for inverter in response_inventory["Inventory"]["inverters"]:  #inverterlerin seri nolarÄ±nÄ± Ã§Ä±karÄ±p ayrÄ± bir listeye ekliyorum.
            inverters.append(inverter["SN"])

            connected_optimizer += inverter["connectedOptimizers"] 
        if endTime - startTime < datetime.timedelta(weeks=1):
            st.info("AralÄ±k Bir Haftadan KÄ±sa SeÃ§ilemez, AralÄ±k Uygun olacak ÅŸekilde BitiÅŸ Tarihi GÃ¼ncellenmiÅŸtir.")
            startTime = endTime - datetime.timedelta(days=6)

        tarih = pd.date_range(startTime,endTime, freq="6D").to_series()
        tarih = tarih.apply(lambda x: x.strftime("%Y-%m-%d"))
        tarih=tarih.to_list()
        
        counter = 1
        
        try:
            with st_lottie_spinner(lottie_hamster, key="download", height=300, quality="high"):       #inverter listesindeki inverter no'lar ile seÃ§ilen tarih aralÄ±ÄŸÄ±nÄ± haftalara bÃ¶lÃ¼p istek atÄ±yor ve en son tÃ¼m verileri birleÅŸtiriyor.
                for sn in inverters:
                    for i in range(len(tarih)-1):
                        startTime=tarih[i]
                        endTime=tarih[i+1]
                        try:
                            data = fetchData(siteID=siteID, startTime=startTime,endTime=endTime,inverterSN=sn,api_key=api_key,counter=counter,dataTypes=st.session_state["selectedDataTypes"])
                        except Exception as e:
                            print(e)
                            pass
                        frameList.append(data)
                    counter +=1   
                mixed = pd.concat(frameList)
                st.write(mixed)
        
        except Exception as e:
            print(e)
            #sys.exit("Data AlÄ±namadÄ±, LÃ¼tfen Sonra Tekrar Deneyiniz.")
            mixed = pd.DataFrame()
            pass

        st.header("##")
    
        col1, mid, col2 = st.columns([10,15,7.5])

        if not mixed.empty:
            with col1:
                with st.spinner("CSV DosyasÄ± HazÄ±rlanÄ±yor.."):
                    csv = csvCreator()
                    st.download_button(
                                "Download as CSV",
                                csv,
                                "file.csv",
                                "text/csv",
                                key='download-csv'
                                )
            with col2:
                with st.spinner("Excel DosyasÄ± HazÄ±rlanÄ±yor.."):
                    buffer =excelCreator()
                    st.download_button(
                            label="Download as XLSX",
                            data=buffer,
                            file_name="file_name_Yield.xlsx",
                            mime="application/vnd.ms-excel"
                            )
        else: st.error("Santral BazÄ±nda GÃ¼nlÃ¼k Limit AÅŸÄ±mÄ± ve / veya DatalarÄ±n BaÅŸlangÄ±Ã§ Tarihinden Ã–nce SeÃ§ilmiÅŸ BaÅŸlangÄ±Ã§ Tarihi.") 
    if sitedetails: #site details section
        sitedetailsdatas = siteDetailsData(siteID,api_key)
        response_inventory = requests.get(f"{baseUrl}/site/{siteID}/inventory?api_key={api_key}").json() #Api'ye json formatÄ±nda istek atÄ±yorum.
        for inverter in response_inventory["Inventory"]["inverters"]:
            inverters.append(inverter["SN"])  #inverterlerin seri nolarÄ±nÄ± Ã§Ä±karÄ±p ayrÄ± bir listeye ekliyorum.
            connected_optimizer += inverter["connectedOptimizers"] 
        sitePeakPower = sitedetailsdatas["peakPower"]
        pd.to_numeric(sitePeakPower)    
        siteName = sitedetailsdatas["name"].str.cat()
        siteinsDate =sitedetailsdatas["installationDate"].str.cat()
        siteMaxPower = sitedetailsdatas["primaryModule.maximumPower"]
        pd.to_numeric(siteMaxPower) 
        siteCity = sitedetailsdatas["location.city"].str.cat()
        siteTown = sitedetailsdatas["location.address"].str.cat()
        siteImageUrl=sitedetailsdatas["uris.SITE_IMAGE"].str.cat()
        st.header(siteName)
        st.image(f"{baseUrl}{siteImageUrl}?api_key={api_key}" )
        inverterCount = len(inverters)
        maxCall = math.floor(290 / (inverterCount * 4))

        col1, gap1, col2, gap2, col3 = st.columns([3,2,4,2,3])
        with col1:
            st.metric(label = "Peak Power (kWp)" ,value = sitePeakPower)
        with col2:
            st.metric(label = "Installed" ,value = siteinsDate)
        with col3:
            st.metric(label="Connected Optimizers", value=connected_optimizer)
        #st.metric(label = "Site Max Power" ,value = siteMaxPower)
        col1, gap1, col2, gap2, col3 = st.columns([3,2,4,2,3])
        with col1:
            st.metric(label="Inverter Count", value=inverterCount)
        with col2:
            st.metric(label="Max. Request at Once", value=f"{maxCall} Months")
        st.metric(label = "City" ,value = siteCity)
        st.metric(label = "Address" ,value = siteTown)
        
 